{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "from transformers import BertModel, BertTokenizer\n",
    "import numpy as np \n",
    "import math\n",
    "\n",
    "\n",
    "from Data import PKLS_FILES\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
    "bert_model = BertModel.from_pretrained('bert-base-cased')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_relation_embedings(relations):\n",
    "    tokenizer =bert_tokenizer\n",
    "    model = bert_model\n",
    "    model.eval()\n",
    "    relation_embedings = []\n",
    "    for label in relations:\n",
    "        inputs = tokenizer(label, return_tensors=\"pt\")\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs, output_hidden_states=True)\n",
    "        \n",
    "        hidden_states = outputs.hidden_states \n",
    "        \n",
    "        last_layer = hidden_states[-1].squeeze(0) # (seq_len, hidden_size)\n",
    "        before_last_layer = hidden_states[-2].squeeze(0)\n",
    "        \n",
    "        average_layers = (last_layer + before_last_layer) / 2.0\n",
    "        r_j = average_layers.mean(dim=0)\n",
    "        \n",
    "        relation_embedings.append(r_j)\n",
    "        \n",
    "    return relation_embedings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "\n",
    "class SentencesDS(Dataset):\n",
    "    def __init__(self, descriptions, max_length=128):\n",
    "        self.descriptions_dict = descriptions\n",
    "        self.ids = list(descriptions.keys())\n",
    "        self.sentences = list(descriptions.values())\n",
    "        \n",
    "        encoded = bert_tokenizer(self.sentences, padding=True, truncation=True, return_tensors=\"pt\", max_length=max_length)\n",
    "        input_ids = encoded['input_ids']\n",
    "        attention_mask = encoded['attention_mask']\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            bert_output = bert_model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            self.embeddings = bert_output.last_hidden_state # (batch_size, seq_len ,hidden_size)\n",
    "        \n",
    "        mask_expanded = attention_mask.unsqueeze(-1).expand(self.embeddings.size())\n",
    "\n",
    "        masked_embeddings = self.embeddings * mask_expanded\n",
    "\n",
    "        sum_embeddings = masked_embeddings.sum(dim=1)  # [batch, hidden_size]\n",
    "        token_counts = mask_expanded.sum(dim=1)  # [batch, 1]\n",
    "        token_counts = token_counts.clamp(min=1)\n",
    "\n",
    "        self.hg  =  sum_embeddings / token_counts # [batch, hidden_size]\n",
    "        \n",
    "        \n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        return  {\"string\": self.sentences[idx], \"hg\": self.hg[idx], \"embedding\": self.embeddings[idx], \"id\": self.ids[idx] }\n",
    "\n",
    "    def getitem_byid(self,desc_id):\n",
    "        idx = self.ids.index(desc_id)\n",
    "        return self.__getitem__(idx)\n",
    "    \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ids) \n",
    "\n",
    "\n",
    "class RelationsDS(Dataset):\n",
    "    def __init__(self, relations_dict, relations_transe_embs):\n",
    "        self.relations_dict = relations_dict \n",
    "        self.ids = list(relations_dict.keys())\n",
    "        self.relations_lst = list(relations_dict.values())\n",
    "        embeddings_list = get_relation_embedings(self.relations_lst)\n",
    "        self.embeddings = torch.stack(embeddings_list, dim=0)  #(num_relations, hidden_size)\n",
    "        self.transe_embeddings = relations_transe_embs\n",
    "        \n",
    "        \n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        return {\"string\": self.relations_lst[idx],   \"id\":self.ids[idx], \"embedding\": self.embeddings[idx]}\n",
    "     \n",
    "\n",
    "    def getitem_byid(self,relation_id):\n",
    "        idx = self.ids.index(relation_id)\n",
    "        return self.__getitem__(idx)\n",
    "    \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ids) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters:\n",
    "- token_embeddings with shape (batch_size, seq_len, hidden_size)\n",
    "- start_probs, end_probs are shape (batch_size, seq_len) \n",
    "- threshold (the probability that is above the threshold) -> consider it a subject start or end \n",
    "\n",
    "Function: \n",
    "- For each sentence in the batch, find indices having probabilities above the threshold \n",
    "- For each start index, find the nearest end index \n",
    "- Compute Sk which would be the average of the start token and the end token embeddings\n",
    "- stack subject embeddings for each sentence \n",
    "- pad all sentences to the seq_len  and create corresponding mask of booleans indicating valid subjects embeddings\n",
    "- apply linear transformation Ws to the padded tensor\n",
    "- Return subject_embeddings containing sk and tuples containing indices (start, end) of the subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_subject_embeddings(token_embeddings, start_probs, end_probs, threshold=.5 ):\n",
    "    batch_size, seq_len, hidden_size=  token_embeddings.shape \n",
    "\n",
    "    subjs_list = [] # list (len = batch_size) of tensors (n_subs, hidden_size)\n",
    "    masks_list = []\n",
    "    subjects_idxs = []\n",
    "\n",
    "    for b in range(batch_size):\n",
    "        start_idxs = (start_probs[b] > threshold).nonzero(as_tuple = True)[0]\n",
    "        end_idxs = (end_probs[b] > threshold).nonzero(as_tuple = True)[0]\n",
    "        subject_embeddings = []\n",
    "        used_ends = set()\n",
    "        sub_idxs_sentence = []\n",
    "        for start in start_idxs:\n",
    "            valid_ends = [e.item() for e in end_idxs if e.item() >= start.item() and e.item() not in used_ends]\n",
    "            if valid_ends:\n",
    "                end = valid_ends[0]\n",
    "                used_ends.add(end)\n",
    "                s_k = (token_embeddings[b, start] + token_embeddings[b, end]) / 2.0\n",
    "                subject_embeddings.append(s_k)\n",
    "                sub_idxs_sentence.append((start.item(),end))\n",
    "                \n",
    "        if len(subject_embeddings) > 0:\n",
    "            subjs_tensor = torch.stack(subject_embeddings, dim=0)# (n_subs, hidden_size)\n",
    "            subjs_list.append(subjs_tensor)\n",
    "            masks_list.append(torch.ones(subjs_tensor.shape[0], dtype=torch.bool, device=token_embeddings.device))\n",
    "        else:\n",
    "            subjs_list.append(torch.empty(0, hidden_size, device=token_embeddings.device))\n",
    "            masks_list.append(torch.empty(0, dtype=torch.bool, device=token_embeddings.device))\n",
    "        subjects_idxs.append(sub_idxs_sentence)\n",
    "    padded_subjects = pad_sequence(subjs_list, batch_first=True, padding_value=0)         # (batch_size, seq_len)\n",
    "    padded_mask = pad_sequence(masks_list, batch_first=True, padding_value=False)\n",
    "    return padded_subjects, padded_mask,  subjects_idxs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_obj_spans_relation(obj_start_probs, obj_end_probs, threshold):\n",
    "  \n",
    "  seq_len = obj_start_probs.shape[0]\n",
    "  obj_idxs = []\n",
    "  used_ends = set()\n",
    "  for tk_idx in range(seq_len):\n",
    "    if obj_start_probs[tk_idx] > threshold:\n",
    "      for j in range(tk_idx, seq_len):\n",
    "        if obj_end_probs[j] > threshold and j not in used_ends:\n",
    "          obj_idxs.append((tk_idx, j))\n",
    "          used_ends.add(j)\n",
    "          break\n",
    "  return obj_idxs\n",
    "\n",
    "\n",
    "def extract_triples(token_embs, subjects_idxs, obj_start_probs, obj_end_probs, threshold=.5):\n",
    "  batch_size, seq_len, num_relations = obj_start_probs.shape\n",
    "  batch_triples = []\n",
    "  for sentence_idx in range(batch_size):\n",
    "    sentence_triples = []\n",
    "    subj_spans = subjects_idxs[sentence_idx] #[(s_start, s_end), ...]\n",
    "\n",
    "    for rel_idx in range(num_relations):\n",
    "      obj_start_sentence = obj_start_probs[sentence_idx, :, rel_idx] #probabilities of this sentence with this relation of all tokens \n",
    "      obj_end_sentence = obj_end_probs[sentence_idx, :, rel_idx] # vector with size (seq_len)\n",
    "      \n",
    "      obj_idxs = extract_obj_spans_relation(obj_start_sentence, obj_end_sentence, threshold) \n",
    "      for subj in subj_spans:\n",
    "        for obj in obj_idxs:\n",
    "          sentence_triples.append((subj, rel_idx , obj))\n",
    "      batch_triples.append(sentence_triples)\n",
    "  return batch_triples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyBRASKModel(nn.Module):\n",
    "    def __init__(self,  hidden_size=768):\n",
    "        super(MyBRASKModel, self).__init__()\n",
    "        self.bert = bert_model \n",
    "        \n",
    "        self.start_subject_fc = nn.Linear(hidden_size, 1)\n",
    "        self.end_subject_fc = nn.Linear(hidden_size, 1)\n",
    "        \n",
    "        self.start_object_fc = nn.Linear(hidden_size, 1)\n",
    "        self.end_object_fc = nn.Linear(hidden_size, 1)\n",
    "        \n",
    "        \n",
    "        #I will put after starT_object_fc and end_object_fc. \n",
    "        \n",
    "        \n",
    "        self.W_r = nn.Linear(hidden_size, hidden_size)\n",
    "        self.W_g = nn.Linear(hidden_size, hidden_size)\n",
    "        self.W_x = nn.Linear(hidden_size, hidden_size)\n",
    "        self.V   = nn.Linear(hidden_size, 1)  \n",
    "        \n",
    "        \n",
    "        self.W_s = nn.Linear(hidden_size, hidden_size)\n",
    "        self.W_x2 = nn.Linear(hidden_size, hidden_size)\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, descriptions_dataset, relation_dataset):\n",
    "\n",
    "        batch_size = descriptions_dataset.embeddings.shape[0]\n",
    "        token_embs = descriptions_dataset.embeddings # (batch_size, seq_len, hidden_size)\n",
    "        \n",
    "        \n",
    "        \n",
    "        print(f\"batch_size: {batch_size}\")\n",
    "        #apply linear + sigmoid to each token \n",
    "        sub_start_probs = self.sigmoid(self.start_subject_fc(token_embs )).squeeze(-1) # (batch_size, seq_len)\n",
    "        sub_end_probs = self.sigmoid(self.end_subject_fc(token_embs)).squeeze(-1) \n",
    "        \n",
    "        padded_subjects, padded_mask,subjects_idxs   = extract_subject_embeddings(\n",
    "            token_embs, sub_start_probs, sub_end_probs, threshold=0.5\n",
    "        ) # padded_subjects (batch_size, seq_len, hidden_size)\n",
    "        s_k_w = self.W_s(padded_subjects)\n",
    "        s_k_w = s_k_w * padded_mask.unsqueeze(-1).float() #(batch_size, seq_len, hidden_size)\n",
    "\n",
    "\n",
    "        h_g = descriptions_dataset.hg # (batch_size, hidden_size)\n",
    "        relations_embeddings = relation_dataset.embeddings #(num_relations, hidden_size)\n",
    "        #backward relation embeddings\n",
    "        b_relations_embeddings = relation_dataset.transe_embeddings #(num_relations, 80)\n",
    "\n",
    "                \n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "        token_embs_exp = token_embs.unsqueeze(2) #(batch_size, seq_len, 1, hidden_size) \n",
    "        h_g_exp = h_g.unsqueeze(1).unsqueeze(2) #(batch_size, 1,1 , hidden_size)\n",
    "        relation_exp = relations_embeddings.unsqueeze(0).unsqueeze(1)  #(1, 1, num_relations, hidden_size)\n",
    "        relation_exp = relation_exp.expand(batch_size, -1, -1, -1) #(batch_size, 1, num_relations, hidden_size) #repeat through the batch\n",
    "\n",
    "        \n",
    "        #attention scores\n",
    "        #tanh to add nonlinearity\n",
    "        e = torch.tanh(\n",
    "            self.W_r(relation_exp) + self.W_g(h_g_exp) + self.W_x(token_embs_exp)\n",
    "        ) # (batch_size, seq_len, num_relations, hidden_size)\n",
    "        #self.V is linear (hidden, 1) because we want a scalar value for each token (to calculate the relevance between the token and the relation)\n",
    "        v_e = self.V(e).squeeze(-1)  # shape: (batch_size, seq_len, num_relations)\n",
    "        \n",
    "        #normalize attention score\n",
    "        #on dim = 1 because on the sentences dimension because we want to distribute attention on tokens, like we want to get probability distribution for all tokens if they are relevant to the relation\n",
    "        A = F.softmax(v_e, dim=1)  # (batch_size, seq_len, num_relations) \n",
    "        A_exp = A.unsqueeze(-1) # (batch_size, seq_len, num_relations, 1)\n",
    "        C = torch.sum(A_exp * token_embs_exp, dim=1)  # (batch_size ,num_relations, hidden_size)\n",
    "        \n",
    "        W_x_xi = self.W_x2(token_embs) #(batch_size, seq_len,  hidden_size)\n",
    "        h_i_k = s_k_w + W_x_xi #(batch_size, seq_len,  hidden_size)\n",
    "        h_i_k_exp = h_i_k.unsqueeze(2) #(batch_size, seq_len, 1,  hidden_size)\n",
    "        \n",
    "        \n",
    "        C_exp = C.unsqueeze(1) # (batch_size, 1 ,num_relations, hidden_size)\n",
    "        # token_embs_exp (batch_size, seq_len, 1, hidden_size) \n",
    "        h_i_j = C_exp + token_embs_exp  # (batch_size, seq_len, num_relations, hidden_size) \n",
    "        \n",
    "        \n",
    "        H_i_j_k = h_i_j + h_i_k_exp\n",
    "        \n",
    "        \n",
    "        #For each sentence, for each token, for each relation, what is the probability that this token is the start (or end) of the object?\n",
    "        obj_start_probs = self.sigmoid(self.start_object_fc(H_i_j_k )).squeeze(-1) # (batch_size, seq_len, num_relations)\n",
    "        obj_end_probs = self.sigmoid(self.end_object_fc(H_i_j_k)).squeeze(-1)  # (batch_size, seq_len, num_relations)\n",
    "        \n",
    "        forward_triples  = extract_triples(token_embs, subjects_idxs, obj_start_probs, obj_end_probs)\n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([75, 768])\n",
      "batch_size: 10\n",
      "h_g_exp shape: torch.Size([10, 1, 1, 768])\n",
      "token_exp shape: torch.Size([10, 128, 1, 768])\n",
      "relation_exp shape: torch.Size([10, 1, 75, 768])\n",
      "e shape: torch.Size([10, 128, 75])\n",
      "A shape: torch.Size([10, 128, 75])\n",
      "C shape: torch.Size([10, 75, 768])\n"
     ]
    }
   ],
   "source": [
    "from Data import PKLS_FILES\n",
    "\n",
    "\n",
    "k  = 10_000\n",
    "\n",
    "descriptions = PKLS_FILES[\"descriptions_normalized\"][k]\n",
    "\n",
    "descriptions_dataset = SentencesDS(descriptions_f)\n",
    "relations = get_relations_dict_from_descriptions(descriptions_dataset.descriptions_dict, relations_f)\n",
    "relations_dataset = RelationsDS(relations)\n",
    "print(relations_dataset.embeddings.shape)\n",
    "\n",
    "\n",
    "model = SubjectPredictor()\n",
    "start_probs = model(descriptions_dataset, relations_dataset)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
