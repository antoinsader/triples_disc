{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Data import get_min_descriptionsNorm_triples_relations, LOGGER_FILES, PKLS_FILES\n",
    "from utils.utils import read_cached_array, cache_array, get_logger\n",
    "from transformers import BertTokenizerFast\n",
    "from flashtext import KeywordProcessor\n",
    "from transformers import BertModel\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import BertModel, BertTokenizer\n",
    "from utils.model_helpers import get_h_gs, extract_first_embeddings,extract_last_idxs, extract_triples,  merge_triples\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing compare with extracted triples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.]) tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.])\n",
      "[((1, 7), (13, 13)), ((1, 7), (23, 23)), ((1, 7), (40, 40)), ((1, 7), (15, 15))]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([13, 15, 23, 40]),)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "k = 1000\n",
    "\n",
    "silver_spans_file = PKLS_FILES[\"silver_spans\"][k]\n",
    "golden_triples_file = PKLS_FILES[\"golden_triples\"][k]\n",
    "silver_spans  = read_cached_array(silver_spans_file)\n",
    "golden_triples_all  = read_cached_array(golden_triples_file)\n",
    "idxs_not_empty_triples = [idx for idx, (_,v) in enumerate(golden_triples_all.items()) if v[\"triples\"] != []]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3364, 128])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "silver_spans[\"head_end\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "entity_process_idx = idxs_not_empty_triples[5]\n",
    "entity_process_correct_triples =   golden_triples_all[ list(golden_triples_all.keys())[entity_process_idx]  ][\"triples\"]\n",
    "\n",
    "correct_head_start_spans, correct_head_end_spans, correct_tail_start_spans, correct_tail_end_spans = silver_spans[\"head_start\"], silver_spans[\"head_end\"], silver_spans[\"tail_start\"], silver_spans[\"tail_end\"]\n",
    "entity_correct_head_start_spans, entity_correct_head_end_spans, entity_correct_tail_start_spans, entity_correct_tail_end_spans = correct_head_start_spans[entity_process_idx], correct_head_end_spans[entity_process_idx], correct_tail_start_spans[entity_process_idx], correct_tail_end_spans[entity_process_idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size, DESCRIPTION_MAX_LENGTH = correct_head_start_spans.shape\n",
    "\n",
    "model_head_start_probs = np.zeros((batch_size, DESCRIPTION_MAX_LENGTH))\n",
    "model_head_end_probs = np.zeros((batch_size, DESCRIPTION_MAX_LENGTH))\n",
    "model_tail_start_probs = np.zeros((batch_size, DESCRIPTION_MAX_LENGTH))\n",
    "model_tail_end_probs = np.zeros((batch_size, DESCRIPTION_MAX_LENGTH))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# introduce wrong triples for the process entity model head_start....\n",
    "\n",
    "for h_idxs, t_idxs in entity_process_correct_triples + [((0,0), (13,13))]:\n",
    "    model_head_start_probs[entity_process_idx, h_idxs[0]], model_head_end_probs[entity_process_idx, h_idxs[1]], model_tail_start_probs[entity_process_idx, t_idxs[0]], model_tail_end_probs[entity_process_idx, t_idxs[1]] = .9, .9, .9, .9\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((1, 7), (13, 13)),\n",
       " ((1, 7), (23, 23)),\n",
       " ((1, 7), (40, 40)),\n",
       " ((1, 7), (15, 15))]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entity_process_correct_triples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.48158907890319824\n"
     ]
    }
   ],
   "source": [
    "# Example to understand bce \n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "p = torch.tensor([0.9, 0.9, 0.0, 0.0, 0.0])\n",
    "y = torch.tensor([0.0,  1.0, 0.0, 0.0, 0.0])\n",
    "\n",
    "loss = F.binary_cross_entropy(p, y)\n",
    "print(loss.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.17511335015296936"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bce = nn.BCELoss()\n",
    "\n",
    "loss_fwd = 0.0\n",
    "loss_fwd += bce( torch.tensor(model_head_start_probs).float(), correct_head_start_spans )\n",
    "loss_fwd += bce( torch.tensor(model_head_end_probs).float(), correct_head_start_spans )\n",
    "loss_fwd += bce( torch.tensor(model_).float(), correct_head_start_spans )\n",
    "loss_fwd += bce( torch.tensor(model_head_start_probs).float(), correct_head_start_spans )\n",
    "loss_fwd.item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "subj_start_probs = np.zeros((batch_size, DESCRIPTION_MAX_LENGTH))\n",
    "subj_end_probs = np.zeros((batch_size, DESCRIPTION_MAX_LENGTH))\n",
    "\n",
    "\n",
    "obj_start_probs = np.zeros((batch_size,  DESCRIPTION_MAX_LENGTH))\n",
    "obj_end_probs = np.zeros((batch_size, DESCRIPTION_MAX_LENGTH))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "wrong_triple = ((7,9), (16,18))\n",
    "\n",
    "\n",
    "for subj_idxs, obj_idxs  in [correct_triples[0],correct_triples[2], wrong_triple]:\n",
    "    subj_start_probs[sentence_idx, subj_idxs[0]] = 0.9\n",
    "    subj_end_probs[sentence_idx, subj_idxs[1]] = 0.9\n",
    "    obj_start_probs[sentence_idx, obj_idxs[0]] = 0.9\n",
    "    obj_end_probs[sentence_idx, obj_idxs[1]] = 0.9\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3364\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "encoded = tokenizer(list(descs.values()), padding=\"max_length\", truncation=True, return_tensors=\"pt\", max_length=128)\n",
    "input_ids = encoded['input_ids']\n",
    "attention_mask = encoded['attention_mask']\n",
    "print(len(input_ids))\n",
    "model = BertModel.from_pretrained('bert-base-cased')\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    bert_output = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "    embeddings = bert_output.last_hidden_state # (batch_size, seq_len ,hidden_size)\n",
    "\n",
    "embeddings.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[((1, 6), 0, (16, 18)),\n",
       "  ((1, 6), 0, (21, 22)),\n",
       "  ((1, 6), 0, (38, 39)),\n",
       "  ((7, 9), 0, (16, 18)),\n",
       "  ((7, 9), 0, (21, 22)),\n",
       "  ((7, 9), 0, (38, 39))]]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils.model_helpers import extract_first_embeddings, extract_triples , get_h_gs\n",
    "import torch\n",
    "\n",
    "model = BertModel.from_pretrained('bert-base-cased')\n",
    "\n",
    "_, embs = get_h_gs([description], tokenizer,  model, 128)\n",
    "\n",
    "\n",
    "\n",
    "_, _, f_subj_idxs =  extract_first_embeddings(embs, torch.tensor([subj_start_probs]), torch.tensor([subj_end_probs]), 128, .6)\n",
    "\n",
    "\n",
    "\n",
    "extracted_triples = extract_triples(f_subj_idxs, obj_start_probs, obj_end_probs, True, 0.6)\n",
    "extracted_triples\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "530"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "golden_triples_all = read_cached_array(golden_triples_file)\n",
    "\n",
    "correct_triples_description_ids = [d_id for d_id in golden_triples_all.keys()]\n",
    "correct_triples = [b[\"triples\"] for b in golden_triples_all.values()]\n",
    "len(correct_triples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Q5582517'"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_triples_description_ids[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((1, 6), (21, 22)),\n",
       " ((1, 6), (28, 29)),\n",
       " ((1, 6), (38, 39)),\n",
       " ((1, 6), (25, 26)),\n",
       " ((1, 6), (24, 26))]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_triples[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[81], line 13\u001b[0m\n\u001b[0;32m      8\u001b[0m correct_obj_e \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(batch_size, seq_len)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m b \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(batch_size):\n\u001b[1;32m---> 13\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m s_idxs, o_idxs \u001b[38;5;129;01min\u001b[39;00m correct_triples[b]:\n\u001b[0;32m     14\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m s, e \u001b[38;5;129;01min\u001b[39;00m s_idxs:\n\u001b[0;32m     15\u001b[0m             correct_sub_s[b, s] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "correct_triples = [correct_triples]\n",
    "batch_size= 1\n",
    "seq_len = 128\n",
    "\n",
    "correct_sub_s = torch.zeros(batch_size, seq_len)\n",
    "correct_sub_e = torch.zeros(batch_size, seq_len)\n",
    "correct_obj_s = torch.zeros(batch_size, seq_len)\n",
    "correct_obj_e = torch.zeros(batch_size, seq_len)\n",
    "\n",
    "\n",
    "\n",
    "for b in range(batch_size):\n",
    "    for s_idxs, o_idxs in correct_triples[b]:\n",
    "        for s, e in s_idxs:\n",
    "            correct_sub_s[b, s] = 1.0\n",
    "            correct_sub_e[b, e] = 1.0\n",
    "        for s,e in o_idxs:\n",
    "            correct_obj_s[b,s]= 1.0\n",
    "            correct_obj_e[b,e]= 1.0\n",
    "\n",
    "print(\"correct_triples: \", correct_triples)\n",
    "print(\"correct_sub_s: \" , correct_sub_s)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
