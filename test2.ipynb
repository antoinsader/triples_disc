{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from math import ceil\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from datasets import Dataset as HFDataset\n",
    "from transformers import BertModel, BertTokenizer, BertTokenizerFast\n",
    "import numpy as np \n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import torch.multiprocessing as mp\n",
    "import random\n",
    "import os\n",
    "from multiprocessing import Pool, cpu_count\n",
    "\n",
    "\n",
    "\n",
    "from collections import defaultdict\n",
    "import itertools\n",
    "import random \n",
    "import logging\n",
    "\n",
    "from torch.amp import autocast, GradScaler\n",
    "import re \n",
    "from joblib import Parallel, delayed\n",
    "from joblib import dump, load\n",
    "\n",
    "import concurrent.futures\n",
    "import multiprocessing\n",
    "from functools import partial\n",
    "import unicodedata\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import words\n",
    "\n",
    "import torch \n",
    "import os \n",
    "from transformers import BertTokenizerFast\n",
    "\n",
    "\n",
    "from datasets import Dataset as HFDataset \n",
    "\n",
    "root = \".\"\n",
    "RAW_FOLDER = f\"{root}/data/raw\"\n",
    "RESULTS_FOLDER = f\"{root}/data/results\"\n",
    "HELPERS_FOLDER = f\"{root}/data/helpers\"\n",
    "CHECKPOINT_FOLDER = f\"{root}/data/checkpoints\"\n",
    "TEMP_FOLDER = f\"{root}/data/temp\"\n",
    "\n",
    "RESULT_FILES  = {\n",
    "    \"descriptions_unormalized\": f\"{RESULTS_FOLDER}/descriptions_unormalized.pkl\",\n",
    "    \"descriptions\": f\"{RESULTS_FOLDER}/descriptions.pkl\",\n",
    "    \"aliases\": f\"{RESULTS_FOLDER}/aliases.pkl\",\n",
    "    \"alias_patterns\": f\"{RESULTS_FOLDER}/aliases_patterns.pkl\",\n",
    "    \"relations\": f\"{RESULTS_FOLDER}/relations.pkl\",\n",
    "    \"triples\": f\"{RESULTS_FOLDER}/triples.pkl\",\n",
    "    \"transE_relation_embeddings\": f\"{RESULTS_FOLDER}/transE_rel_embs.pkl\",\n",
    "    \"silver_spans\": {\n",
    "        \"head_start\": f\"{RESULTS_FOLDER}/ss_head_start.npz\",\n",
    "        \"head_end\": f\"{RESULTS_FOLDER}/ss_head_end.npz\",\n",
    "        \"tail_start\": f\"{RESULTS_FOLDER}/ss_tail_start.npz\",\n",
    "        \"tail_end\": f\"{RESULTS_FOLDER}/ss_tail_end.npz\",\n",
    "        \"sentence_tokens\": f\"{RESULTS_FOLDER}/ss_sentence_tokens.pkl\",\n",
    "        \"desc_ids\": f\"{RESULTS_FOLDER}/desc_ids.pkl\",\n",
    "        \n",
    "    }\n",
    "}\n",
    "\n",
    "CHECKPOINTS_FILES = {\n",
    "    \"transe_triples\": f\"{CHECKPOINT_FOLDER}/transe_triples.pkl\",\n",
    "    \"transe_model\": f\"{CHECKPOINT_FOLDER}/transe_model.pth\",\n",
    "}\n",
    "\n",
    "TEMP_FILES = {\n",
    "    \"heads_aliases\": f\"{TEMP_FOLDER}/heads_aliases.pkl\",\n",
    "    \"tails_aliases\": f\"{TEMP_FOLDER}/tails_aliases.pkl\",\n",
    "    \"aliases_patterns\": f\"{TEMP_FOLDER}/aliases_patterns.pkl\",\n",
    "    \"sentences_tokens\": f\"{TEMP_FOLDER}/sentences_tokens.pkl\",\n",
    "    \"results_spans\": f\"{TEMP_FOLDER}/results_spans.pkl\",\n",
    "}\n",
    "\n",
    "def cache_array(ar, filename):\n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump(ar, f)\n",
    "    print(f\"Array chached in file {filename}\")\n",
    "\n",
    "def read_cached_array(filename):\n",
    "    with open(filename, 'rb', buffering=16*1024*1024) as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "def save_tensor(tensor, path):\n",
    "    os.makedirs(os.path.dirname(path) , exist_ok=True)\n",
    "    np.savez_compressed(path, arr=tensor.cpu().numpy())\n",
    "    print(f\"Tensor chached in file {path}\")\n",
    "\n",
    "\n",
    "\n",
    "def read_tensor(path):\n",
    "    print(f\"reading from path {path}\")\n",
    "    loaded = np.load(path)\n",
    "    return torch.from_numpy(loaded[\"arr\"])\n",
    "\n",
    "\n",
    "def split_list(data, num_chunks):\n",
    "    chunk_size = (len(data) + num_chunks - 1) // num_chunks  # ceiling division\n",
    "    return [data[i * chunk_size : (i + 1) * chunk_size] for i in range(num_chunks)]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(batch, tokenizer, max_length):\n",
    "    return tokenizer(\n",
    "        batch[\"text\"],\n",
    "        padding=\"max_length\",\n",
    "        truncation=True, \n",
    "        return_tensors=\"pt\",\n",
    "        max_length = max_length\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptions = read_cached_array(RESULT_FILES[\"descriptions\"])\n",
    "\n",
    "sentences = list(descriptions.values())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = HFDataset.from_dict({\"text\": sentences})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text'],\n",
       "    num_rows: 736\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded = dataset.map(\n",
    "    tokenize_function,\n",
    "    batched=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "attention_masks = torch.tensor([\n",
    "    [1,1,0,0,0],\n",
    "    [1,1,1,0,0],\n",
    "]).unsqueeze(-1)\n",
    "attention_masks.shape  #(2,5,1)\n",
    "\n",
    "embs = torch.tensor([\n",
    "    [ [1,2,3,1,2], [2,2,2,2,2], [3,3,3,3,3], [3,2,3,1,4], [5,4,1,5,6]  ],\n",
    "    [ [1,1,1,1,1], [8,8,7,7,10], [20,40,20,60,20], [30,70,35,25,40], [50,40,10,50,60]  ],\n",
    "])\n",
    "\n",
    "# sum_embs = (embs * attention_masks).sum(dim=1)\n",
    "# token_counts = attention_masks.sum(dim=1).clamp(min=1)\n",
    "\n",
    "# print(sum_embs)\n",
    "# print(token_counts)\n",
    "# sum_embs / token_counts\n",
    "\n",
    "embs.shape[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def extract_first_embeddings(token_embs, start_probs, end_probs, max_len, threshold=.6):\n",
    "    \"\"\"\n",
    "        args:\n",
    "            token_embs: sentence embeddings with shape (batch_size, seq_length, hidden_size)\n",
    "            start_probs: probabilities that an entity is a start (start of subject for forward, start of object for backward) with shape (batch_size, seq_len)\n",
    "            end_probs: probabilities that an entity is an end (end of subject for forward, end of object for backward) with shape (batch_size, seq_len)\n",
    "            threshold: threshold that if the probability > threshold, then it is considered start or end of starting entity\n",
    "        returns:\n",
    "            padded_embs: these are padded embeddings of all subjects or objects with shape (B, max_ents, H)\n",
    "            mask_embs: mask to show the padded embs (0 for padding)\n",
    "            head_idxs: list (len=batch_size) where each item is a list of tuples, each tuple (start_idx, end_idx) of the entities\n",
    "    \"\"\"\n",
    "    batch_size, seq_len, hidden_size = token_embs.shape\n",
    "\n",
    "    start_mask = start_probs > threshold\n",
    "    end_mask = end_probs > threshold\n",
    "\n",
    "    head_idxs = []\n",
    "    all_ents_embs = []\n",
    "    all_masks = []\n",
    "\n",
    "    for sent_idx in range(batch_size):\n",
    "        print()\n",
    "        print(f\"sent idx: {sent_idx}\")\n",
    "        start_indices = torch.where(start_mask[sent_idx])[0]\n",
    "        end_indices = torch.where(end_mask[sent_idx])[0]\n",
    "\n",
    "        ents_embs = []\n",
    "        idxs_sentence = []\n",
    "        used_ends = set()\n",
    "\n",
    "        for start_idx in start_indices.tolist():\n",
    "            print(f\"    start idx: {start_idx}\")\n",
    "            end_ptr = 0 \n",
    "            while end_ptr < len(end_indices) and (  end_indices[end_ptr].item() < start_idx or end_indices[end_ptr].item() in used_ends) :\n",
    "                print(f\"        end ptr: {end_ptr}\")\n",
    "                end_ptr += 1\n",
    "            if end_ptr < len(end_indices):\n",
    "                end = end_indices[end_ptr].item()\n",
    "                used_ends.add(end)\n",
    "                idxs_sentence.append((start_idx, end))\n",
    "\n",
    "                #compute average embedding (in paper shows ((emb of start + emb of end) / 2), I will do between them )\n",
    "                sum = token_embs[sent_idx , start_idx : end + 1].sum(dim=0)\n",
    "                dominator = end + 1 - start_idx\n",
    "                ent_emb = sum / dominator\n",
    "                ents_embs.append(ent_emb)\n",
    "\n",
    "        head_idxs.append(idxs_sentence)\n",
    "\n",
    "        if ents_embs:\n",
    "            ent_tensor = torch.stack(ents_embs)\n",
    "            all_ents_embs.append(ent_tensor)\n",
    "            all_masks.append(torch.ones(ent_tensor.size(0), dtype=torch.bool, device=token_embs.device))\n",
    "        else:\n",
    "            all_ents_embs.append(torch.empty(0, hidden_size, device=token_embs.device))\n",
    "            all_masks.append(torch.zeros(0, dtype=torch.bool, device=token_embs.device))\n",
    "\n",
    "    # Pad sequences\n",
    "    padded_embs = pad_sequence(all_ents_embs, batch_first=True, padding_value=0.0)\n",
    "    mask_embs = pad_sequence(all_masks, batch_first=True, padding_value=False)\n",
    "\n",
    "    if max_len is not None:\n",
    "        # Pad or truncate embeddings\n",
    "        curr_len = padded_embs.size(1)\n",
    "        if curr_len < max_len:\n",
    "            pad_size = max_len - curr_len\n",
    "            padding = torch.zeros(padded_embs.size(0), pad_size, padded_embs.size(2), device=padded_embs.device)\n",
    "            padded_embs = torch.cat([padded_embs, padding], dim=1)\n",
    "\n",
    "            mask_padding = torch.zeros(mask_embs.size(0), pad_size, dtype=torch.bool, device=mask_embs.device)\n",
    "            mask_embs = torch.cat([mask_embs, mask_padding], dim=1)\n",
    "\n",
    "        elif curr_len > max_len:\n",
    "            padded_embs = padded_embs[:, :max_len, :]\n",
    "            mask_embs = mask_embs[:, :max_len]\n",
    "\n",
    "    return padded_embs, mask_embs, head_idxs\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_probs = torch.tensor([\n",
    "    [.6,.6,.3,.3],\n",
    "    [.1,.6,.3,.3],\n",
    "    [.3,.6,.3,.3]\n",
    "])\n",
    "end_probs = torch.tensor([\n",
    "    [.6,.3,.3,.6],\n",
    "    [.3,.3,.3,.6],\n",
    "    [.6,.3,.3,.3]\n",
    "])\n",
    "\n",
    "\n",
    "token_embs = torch.tensor([\n",
    "    [[4,2,1,6, 5,9], [1,7,9,3,5,6], [4,7,1,7,3,2], [3,1,9,3,1,4]],\n",
    "    [[4,2,1,6, 5, 9], [1,7,9,3,5,6], [4,7,1,7,3,2], [3,1,9,3,1,4]],\n",
    "    [[4,2,1,6, 5, 9], [1,7,9,3,5,6], [4,7,1,7,3, 2], [3,1,9,3,1,4]],\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "sent idx: 0\n",
      "    start idx: 0\n",
      "    start idx: 1\n",
      "        end ptr: 0\n",
      "\n",
      "sent idx: 1\n",
      "    start idx: 1\n",
      "\n",
      "sent idx: 2\n",
      "    start idx: 1\n",
      "        end ptr: 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[4.0000, 2.0000, 1.0000, 6.0000, 5.0000, 9.0000],\n",
       "         [2.6667, 5.0000, 6.3333, 4.3333, 3.0000, 4.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
       "\n",
       "        [[2.6667, 5.0000, 6.3333, 4.3333, 3.0000, 4.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
       "\n",
       "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_embs, mask_embs, head_idxs = extract_first_embeddings(token_embs, start_probs, end_probs, 4, threshold=.5)\n",
    "\n",
    "padded_embs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
